{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex_tf_hub_transfer_learning_cassava_efficientnet/b4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za8-Nr5k11fh"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Eq10uEbw0E4l"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYM61xrTsP5d"
      },
      "source": [
        "# Rock, Paper & Scissors with TensorFlow Hub - TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWFpUd1yy3gt"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%202/Exercise/TFLite_Week2_Exercise_Answer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/lmoroney/dlaicourse/blob/master/TensorFlow%20Deployment/Course%202%20-%20TensorFlow%20Lite/Week%202/Exercise/TFLite_Week2_Exercise_Answer.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL54LWCHt5q5"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "110fGB18UNJn"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except:\n",
        "    pass\n",
        "# Load the TensorBoard notebook extension.\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlauq-4FWGZM"
      },
      "source": [
        "from datetime import datetime\n",
        "import io\n",
        "import itertools\n",
        "from packaging import version\n",
        "from six.moves import range\n",
        "import sklearn.metrics\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"\\u2022 Using TensorFlow Version:\", tf.__version__)\n",
        "print(\"\\u2022 Using TensorFlow Hub Version: \", hub.__version__)\n",
        "print('\\u2022 GPU Device Found.' if tf.test.is_gpu_available() else '\\u2022 GPU Device Not Found. Running on CPU')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmaHHH7Pvmth"
      },
      "source": [
        "## Select the Hub/TF2 Module to Use\n",
        "\n",
        "Hub modules for TF 1.x won't work here, please use one of the selections provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2L_ov9UuA8c"
      },
      "source": [
        "module_selection = (\"efficientnet/b4\", 380, 1280) #@param [\"(\\\"mobilenet_v2\\\", 224, 1280)\", \"(\\\"inception_v3\\\", 299, 2048)\" ,\"(\\\"efficientnet/b4\\\", 380, 1280)\"] {type:\"raw\", allow-input: true}\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\"\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYUsgwCBv87A"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nqVX3KYwGPh"
      },
      "source": [
        "Use [TensorFlow Datasets](http://tensorflow.org/datasets) to load the cats and dogs dataset.\n",
        "\n",
        "This `tfds` package is the easiest way to load pre-defined data. If you have your own data, and are interested in importing using it with TensorFlow see [loading image data](../load_data/images.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGvpkDj4wBup"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkF4Boe5wN7N"
      },
      "source": [
        "The `tfds.load` method downloads and caches the data, and returns a `tf.data.Dataset` object. These objects provide powerful, efficient methods for manipulating data and piping it into your model.\n",
        "\n",
        "Since `\"cats_vs_dog\"` doesn't define standard splits, use the subsplit feature to divide it into (train, validation, test) with 80%, 10%, 10% of the data respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ9xK9F2wGD8"
      },
      "source": [
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "#splits = tfds.Split.ALL.subsplit(weighted=(80, 10, 10))\n",
        "\n",
        "splits, info = tfds.load('cassava', with_info=True, as_supervised=True, split = ['train', 'validation' ,'test' ])\n",
        "\n",
        "(train_examples, validation_examples, test_examples) = splits\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoeKVvbTQXvJ"
      },
      "source": [
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDKYvuJaWbEl"
      },
      "source": [
        "class_names = np.array(info.features['label'].names)\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBDNqv2EKoeH"
      },
      "source": [
        "get_label_name = info.features['label'].int2str\n",
        "#for i in range(num_classes):\n",
        " #print(get_label_name(i))\n",
        "\n",
        "for image, label in train_examples.take(3):\n",
        "  print(image.shape)\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  print(label)\n",
        "  plt.title(get_label_name(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV-yf8YePHwG"
      },
      "source": [
        "train_label = [ label for image, label in train_examples]\n",
        "#print(train_images)\n",
        "\n",
        "# Clear out prior logging data.\n",
        "!rm -rf logs/plots\n",
        "\n",
        "logdir = \"logs/plots/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "file_writer = tf.summary.create_file_writer(logdir)\n",
        "\n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image\n",
        "\n",
        "def image_grid():\n",
        "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
        "  # Create a figure to contain the plot.\n",
        "  figure = plt.figure(figsize=(10,10))\n",
        "  for i in range(25):\n",
        "    # Start next subplot.\n",
        "    plt.subplot(5, 5, i + 1, title=class_names[train_label[i]])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow([image for image, label in train_examples.take(28)][i]) #cmap=plt.cm.binary)\n",
        "  \n",
        "  return figure\n",
        "\n",
        "# Prepare the plot\n",
        "figure = image_grid()\n",
        "# Convert to image and log\n",
        "with file_writer.as_default():\n",
        "  tf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK0ZrabdIb3v"
      },
      "source": [
        "%tensorboard --logdir logs/plots"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmXQYXNWwf19"
      },
      "source": [
        "### Format the Data\n",
        "\n",
        "Use the `tf.image` module to format the images for the task.\n",
        "\n",
        "Resize the images to a fixes input size, and rescale the input channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7UyXblSwkUS"
      },
      "source": [
        "def format_image(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    #image = tf.image.grayscale_to_rgb(image)\n",
        "    image = tf.image.resize(image, IMAGE_SIZE)/ 255.0\n",
        "    #image = tf.keras.layers.experimental.preprocessing.RandomRotation(factor, fill_mode='reflect', interpolation='bilinear')\n",
        "    print(image.get_shape)\n",
        "    return  image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nrDR8CnwrVk"
      },
      "source": [
        "Now shuffle and batch the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAEUG7vawxLm"
      },
      "source": [
        "BATCH_SIZE =  32#@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHEC9mbswxvM"
      },
      "source": [
        "train_batches = train_examples.shuffle(1000).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "\n",
        "cm_validation_batches = validation_examples.map(format_image).batch(2160).prefetch(1)\n",
        "\n",
        "\n",
        "test_batches = test_examples.batch(1).map(format_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJuPzpIyuKi1"
      },
      "source": [
        "from collections import Counter\n",
        "import pandas  as pd\n",
        "\n",
        "counts =[]\n",
        "\n",
        "for _ , train_labels in train_batches.take(1414):\n",
        "  counts.extend(train_labels.numpy())\n",
        "a = dict(Counter(counts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_WUWx4tupmK"
      },
      "source": [
        "print(a)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPJoj5NHuK9N"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "df_dis = pd.DataFrame.from_dict(a , orient='index')\n",
        "df_dis.plot.barh(figsize = (10,7) , legend =False, colormap='Paired' )\n",
        "\n",
        "print(class_names)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAOmQdirv6R0"
      },
      "source": [
        "class_weight = {0: 5.7 ,\n",
        "1: 1.8,\n",
        "2: 3.4,\n",
        "3: 1.0,\n",
        "4: 8.4\n",
        "}\n",
        "\n",
        "# deal with the imbalaced dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghQhZjgEw1cK"
      },
      "source": [
        "Inspect a batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz0xsMCjwx54"
      },
      "source": [
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "\n",
        "image_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9EIdubhyQVe"
      },
      "source": [
        "\n",
        "a,  = cm_validation_batches.take(1)\n",
        "im , l = a[0], a[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(im.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfl3ABGUUbfc"
      },
      "source": [
        "from matplotlib.colors import Normalize\n",
        "import matplotlib.cm  as cm\n",
        "\n",
        "\n",
        "def class_distribution(train_examples , validation_examples , test_examples):\n",
        "        train_label_plot = [ label for image, label in train_examples]\n",
        "        valid_label_plot = [ label for image, label in validation_examples]\n",
        "        test_label_plot = [ label for image, label in test_examples]\n",
        "        unique, counts = np.unique(valid_label_plot, return_counts=True)\n",
        "        #print(unique)\n",
        "\n",
        "        my_cmap = cm.get_cmap('jet')\n",
        "        \n",
        "        # Get normalize function (takes data in range [vmin, vmax] -> [0, 1])\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        my_norm = Normalize(vmin=0, vmax=5)\n",
        "        plt.bar(  unique, counts,color=my_cmap(my_norm(unique)))\n",
        "        #plt.barh (plot the horizontal bar)\n",
        "\n",
        "        plt.xticks(unique, class_names)\n",
        "        plt.title('Class Frequency')\n",
        "        plt.xlabel('Class')\n",
        "        plt.ylabel('Frequency')\n",
        "        plt.show()\n",
        "\n",
        "        fig = plt.gcf\n",
        "\n",
        "        return fig\n",
        "\n",
        "class_distribution(train_examples , validation_examples , test_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS_gVStowW3G"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "All it takes is to put a linear classifier on top of the `feature_extractor_layer` with the Hub module.\n",
        "\n",
        "For speed, we start out with a non-trainable `feature_extractor_layer`, but you can also enable fine-tuning for greater accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaJW3XrPyFiF"
      },
      "source": [
        "do_fine_tuning = True #@param {type:\"boolean\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1nwH2HhKS9W"
      },
      "source": [
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   input_shape=IMAGE_SIZE + (3,), \n",
        "                                   #output_shape=[FV_SIZE],\n",
        "                                   trainable=do_fine_tuning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uRZuazI8Jhx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFqM1WV5KS9b"
      },
      "source": [
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf.keras.Sequential([               \n",
        "        feature_extractor,\n",
        "        tf.keras.layers.Dense(20, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_bUY_IYKS9h"
      },
      "source": [
        "#@title (Optional) Unfreeze some layers\n",
        "NUM_LAYERS = 1 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "      \n",
        "if do_fine_tuning:\n",
        "    feature_extractor.trainable = False\n",
        "    #feature_extractor.trainable = True\n",
        "    # fine tunning from the beginning with the pre-trained weights\n",
        "    \n",
        "    for layer in model.layers[-NUM_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "else:\n",
        "    feature_extractor.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2e5WupIw2N2"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CIsQJz1B4R1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f3yBUvkd_VJ"
      },
      "source": [
        "if do_fine_tuning:\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "else:\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI2NzIQBYRIF"
      },
      "source": [
        "!rm -rf logs/image\n",
        "\n",
        "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "# Define the basic TensorBoard callback.\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
        "file_writer_roc = tf.summary.create_file_writer(logdir + '/roc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz7FobExgKxQ"
      },
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Normalize the confusion matrix.\n",
        "  cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doAndoDqgG9W"
      },
      "source": [
        "\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(im)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "      # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(l, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_names=class_names)\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
        "\n",
        "# Define the per-epoch callback.\n",
        "cm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5u5UnDu1Vrr"
      },
      "source": [
        "!pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zghw7sULNzgh"
      },
      "source": [
        "import scikitplot as skplt\n",
        "\n",
        "def plot_roc(y_true, y_probas):\n",
        "  #figure = plt.figure(figsize=(8, 8))\n",
        "  figure, axes = plt.subplots(1,1, figsize = (8,8))\n",
        "\n",
        "  skplt.metrics.plot_roc_curve(y_true, y_probas , ax =axes ,text_fontsize ='small', figsize= (8 ,8))\n",
        "  plt.title('ROC')\n",
        "  #plt.colorbar()\n",
        "  plt.ylabel('True Label')\n",
        "  plt.xlabel('Predicated Label')\n",
        "  fig = plt.gcf()\n",
        "  #plt.show()\n",
        "  fig.savefig(\"test_rasterization.png\", dpi=150)\n",
        "  #print(fig)\n",
        "  \n",
        "\n",
        "  return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBGmesCQIfEX"
      },
      "source": [
        "def log_roc(epoch, logs):\n",
        "  test_pred_raw = model.predict(im)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "  #print(test_pred.shape)\n",
        "  #print(l.shape)\n",
        "  figure_roc = plot_roc(l, test_pred_raw)\n",
        "  roc_image = plot_to_image(figure_roc)\n",
        "\n",
        "\n",
        "  # Log the roc  as an image summary.\n",
        "  with file_writer_roc.as_default():\n",
        "    tf.summary.image(\"ROC\", roc_image, step=epoch)\n",
        "\n",
        "roc_callback = tf.keras.callbacks.LambdaCallback( on_epoch_end=log_roc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-zzRGF66X8o"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.0001)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_YKX2Qnfg6x"
      },
      "source": [
        "EPOCHS = 60\n",
        "# Start TensorBoard.\n",
        "\n",
        "\n",
        "#%tensorboard --logdir logs\n",
        "\n",
        "\n",
        "\n",
        "hist = model.fit(train_batches,\n",
        "                 validation_data=validation_batches,\n",
        "                 #validation_steps = 10,\n",
        "                 epochs=EPOCHS,\n",
        "                 callbacks=[tensorboard_callback,reduce_lr, early_stopping ]\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0570FDcAormQ"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize = (10, 5))\n",
        "\n",
        "axs[0].plot(hist.history['loss'])\n",
        "axs[0].plot(hist.history['val_loss'])\n",
        "axs[1].plot(hist.history['accuracy'])\n",
        "axs[1].plot(hist.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFvftKRRDgYG"
      },
      "source": [
        "predictions = []\n",
        "real_label  = []\n",
        "for image_batch , labels_batch in test_batches.take(3000):\n",
        "  \n",
        "  predictions.extend(np.argmax(model.predict(image_batch), axis =-1))\n",
        "  real_label.extend(labels_batch.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeIMDaQgGVpm"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "cl_report = classification_report(predictions, real_label, target_names = list(class_names))\n",
        "print(\"The classification report : \\n\", cl_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ecoTMIWHRi7"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "cl_report = classification_report(real_label, predictions, target_names = list(class_names), output_dict = True)\n",
        "sns.heatmap(pd.DataFrame(cl_report).iloc[:-1, :].T, annot = True, linewidths = .5)\n",
        "print(\"List of the class name: \\n\", list(class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD4TgMWqHR2I"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(real_label, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnS3pnjRHmEs"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title = \"Confusion Matrix\",\n",
        "                          cmap = None,\n",
        "                          normalize = True\n",
        "    \n",
        "):\n",
        "\n",
        "\n",
        "  accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "  misclass = 1 - accuracy\n",
        "\n",
        "  if cmap is None:\n",
        "    cmap = plt.get_cmap('Blues')\n",
        "\n",
        "  plt.figure(figsize = (25, 25))\n",
        "  plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
        "  plt.title(title)\n",
        "\n",
        "  if target_names is not None:\n",
        "    tick_marks = np.arange(len(target_names))\n",
        "    plt.xticks(tick_marks, target_names, rotation = 90)\n",
        "    plt.yticks(tick_marks, target_names)\n",
        "\n",
        "  if normalize:\n",
        "    cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
        "\n",
        "  thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      if normalize:\n",
        "          plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "      else:\n",
        "          plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel(\"True label\")\n",
        "  plt.xlabel('Predicted label \\n accuracy = {:0.4f}; ,isclass = {:0.4f}'.format(accuracy, misclass))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnq17zDtJCJm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipfGx3NoHmpX"
      },
      "source": [
        "plot_confusion_matrix(cm = cm,\n",
        "                      target_names = list(class_names),\n",
        "                      title = 'Confusion Matrix',\n",
        "                      cmap = 'inferno_r',\n",
        "                      normalize = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}